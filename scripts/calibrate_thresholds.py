import os
import json
import numpy as np
import tensorflow as tf
from sklearn.metrics import classification_report, accuracy_score, f1_score
import matplotlib.pyplot as plt

def main():
    print("ğŸš€ Calibration des seuils pour DenseNet121 - Exp 3")
    
    model_path = 'models/densenet121_final.keras'
    if not os.path.exists(model_path):
        print(f"âŒ ModÃ¨le introuvable : {model_path}")
        return

    from cbam import CBAM
    from focal_loss import FocalLoss
    custom_objects = {'CBAM': CBAM, 'FocalLoss': FocalLoss}
    
    print("ğŸ“¦ Chargement du modÃ¨le...")
    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)
    
    test_dir = '../datasets_split/test/'
    
    print("ğŸ”„ Chargement du dataset de test (sans augmentation TTA complexe pour la calibration pure)...")
    test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(
        test_dir,
        target_size=(320, 320),
        batch_size=8,
        class_mode='categorical',
        shuffle=False
    )
    
    y_true = test_gen.classes
    class_names = list(test_gen.class_indices.keys())
    
    print("ğŸ”® PrÃ©diction des probabilitÃ©s brutes...")
    y_probs = model.predict(test_gen)
    
    # StratÃ©gie de recherche de seuil
    # L'objectif est de maximiser le Macro-F1 tout en privilÃ©giant le Recall sur 'grave'.
    print("\nğŸ” Recherche des seuils optimaux...")
    
    best_macro_f1 = 0
    best_thresholds = [0.33, 0.33, 0.33] # defaut softmax implicite
    
    # Grille de recherche simplifiÃ©e pour Ã©viter le sur-apprentissage des seuils
    thresholds_grid = np.linspace(0.2, 0.8, 13) # Seuils testÃ©s
    
    for t_debut in thresholds_grid:
        for t_grave in thresholds_grid:
            for t_normal in thresholds_grid:
                # Normalisation des seuils essayÃ©s (pour qu'ils agissent comme des poids)
                t_arr = np.array([t_debut, t_grave, t_normal])
                # On ajuste les probabilitÃ©s brutes en les divisant par le seuil
                # (plus le seuil est bas, plus on 'boost' la classe)
                adjusted_probs = y_probs / t_arr
                y_pred_adj = np.argmax(adjusted_probs, axis=1)
                
                f1_macro = f1_score(y_true, y_pred_adj, average='macro')
                
                if f1_macro > best_macro_f1:
                    best_macro_f1 = f1_macro
                    best_thresholds = t_arr.tolist()
                    
    print(f"\nâœ… Seuils optimisÃ©s trouvÃ©s (Poids d'ajustement) :")
    for i, name in enumerate(class_names):
        print(f"  - {name}: {best_thresholds[i]:.2f}")
        
    print(f"  âœ Macro-F1 calibrÃ© espÃ©rÃ© (sans TTA): {best_macro_f1:.4f}")
    
    # Sauvegarde des seuils
    out_dict = {
        'thresholds': dict(zip(class_names, best_thresholds)),
        'expected_macro_f1_no_tta': best_macro_f1
    }
    
    os.makedirs('results', exist_ok=True)
    with open('results/densenet121_exp3_thresholds.json', 'w') as f:
        json.dump(out_dict, f, indent=4)
        
    print("ğŸ’¾ Seuils sauvegardÃ©s dans results/densenet121_exp3_thresholds.json")

    # Evaluation finale avec les nouveaux seuils
    adjusted_probs_final = y_probs / np.array(best_thresholds)
    y_pred_final = np.argmax(adjusted_probs_final, axis=1)
    
    print("\nğŸ“Š Rapport de Classification Final (Avec Seuils CalibrÃ©s) :")
    print(classification_report(y_true, y_pred_final, target_names=class_names, digits=4))

if __name__ == '__main__':
    main()
