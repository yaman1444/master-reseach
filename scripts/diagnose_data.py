"""
Script de diagnostic pour identifier les problÃ¨mes de donnÃ©es
"""
import numpy as np
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
from collections import Counter

def analyze_dataset(data_dir):
    """Analyser la qualitÃ© et distribution du dataset"""
    
    print("="*80)
    print("DIAGNOSTIC DU DATASET BUSI")
    print("="*80 + "\n")
    
    train_dir = Path(data_dir) / 'train'
    test_dir = Path(data_dir) / 'test'
    
    # 1. VÃ©rifier la structure
    print("ðŸ“ Structure des dossiers:")
    for split in ['train', 'test']:
        split_dir = Path(data_dir) / split
        if not split_dir.exists():
            print(f"   âŒ {split}/ manquant!")
            continue
        
        print(f"\n   {split}/")
        for class_name in ['debut', 'grave', 'normal']:
            class_dir = split_dir / class_name
            if class_dir.exists():
                count = len(list(class_dir.glob('*.png')))
                print(f"      {class_name:10s}: {count:4d} images")
            else:
                print(f"      {class_name:10s}: âŒ MANQUANT")
    
    # 2. Analyser les images
    print("\n\nðŸ“Š Analyse des images:")
    
    all_sizes = []
    all_means = []
    all_stds = []
    
    for split in ['train', 'test']:
        split_dir = Path(data_dir) / split
        if not split_dir.exists():
            continue
            
        for class_name in ['debut', 'grave', 'normal']:
            class_dir = split_dir / class_name
            if not class_dir.exists():
                continue
                
            for img_path in list(class_dir.glob('*.png'))[:10]:  # Sample 10 images
                try:
                    img = Image.open(img_path)
                    img_array = np.array(img)
                    
                    all_sizes.append(img_array.shape[:2])
                    all_means.append(img_array.mean())
                    all_stds.append(img_array.std())
                except Exception as e:
                    print(f"   âš ï¸  Erreur lecture {img_path.name}: {e}")
    
    if all_sizes:
        size_counter = Counter([str(s) for s in all_sizes])
        print(f"\n   Tailles d'images (top 3):")
        for size, count in size_counter.most_common(3):
            print(f"      {size}: {count} images")
        
        print(f"\n   Statistiques pixel (Ã©chantillon):")
        print(f"      Moyenne: {np.mean(all_means):.2f} Â± {np.std(all_means):.2f}")
        print(f"      Std:     {np.mean(all_stds):.2f} Â± {np.std(all_stds):.2f}")
    
    # 3. VÃ©rifier le dÃ©sÃ©quilibre
    print("\n\nâš–ï¸  DÃ©sÃ©quilibre des classes:")
    
    train_counts = {}
    for class_name in ['debut', 'grave', 'normal']:
        class_dir = train_dir / class_name
        if class_dir.exists():
            train_counts[class_name] = len(list(class_dir.glob('*.png')))
    
    if train_counts:
        total = sum(train_counts.values())
        max_count = max(train_counts.values())
        
        for class_name, count in train_counts.items():
            ratio = count / total * 100
            imbalance = max_count / count
            print(f"   {class_name:10s}: {count:4d} ({ratio:5.1f}%) - Imbalance ratio: {imbalance:.2f}x")
    
    # 4. Recommandations
    print("\n\nðŸ’¡ Recommandations:")
    
    if train_counts:
        max_imbalance = max(train_counts.values()) / min(train_counts.values())
        if max_imbalance > 3:
            print("   âš ï¸  DÃ‰SÃ‰QUILIBRE SÃ‰VÃˆRE dÃ©tectÃ© (>3x)")
            print("      â†’ Utiliser class_weights")
            print("      â†’ Augmenter l'augmentation de donnÃ©es")
            print("      â†’ ConsidÃ©rer SMOTE ou oversampling")
        
        if total < 1000:
            print("   âš ï¸  DATASET PETIT (<1000 images)")
            print("      â†’ Augmentation de donnÃ©es FORTE requise")
            print("      â†’ Dropout Ã©levÃ© (0.5-0.6)")
            print("      â†’ Fine-tuning progressif")
    
    print("\n" + "="*80 + "\n")

if __name__ == '__main__':
    analyze_dataset('../datasets')
